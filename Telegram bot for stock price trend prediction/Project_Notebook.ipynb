{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0779c29a",
   "metadata": {},
   "source": [
    "## DATA690_7513_SP2023 Applied Artificial Intelligence For Practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e8656",
   "metadata": {},
   "source": [
    "###  Under the Instruction and guidance of, Professor Len Mancini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84adc0a8",
   "metadata": {},
   "source": [
    "#### Final Project\n",
    "#### Saathyak Rao Kasuganti \n",
    "#### UMBC ID: FV86010\n",
    "#### Email: s219@umbc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d05d02",
   "metadata": {},
   "source": [
    "### Project Title : Predictive Analysis Telegram Bot using Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5f0de",
   "metadata": {},
   "source": [
    "### Hypothesis: The use of a telegram bot that uses a bi-directional LSTM, can very efficiently and conveniently predict the stock price trend for any given stock symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8148a51",
   "metadata": {},
   "source": [
    "### Required Modules and applications for 'JET-FINANCE' Bot:\n",
    "\n",
    "#### 1. Telegram  - To interact with Telegram API and use bot.  \n",
    "#### 2. Pandas – Data analytics tools\n",
    "#### 3. NumPy – Numerical library with math. functions.\n",
    "#### 4. Yfinance – Library to use Yahoo Finance API\n",
    "#### 5. Sklearn – For ML Models.\n",
    "#### 6. Tensorflow – Used for LSTM model and Dense layers.\n",
    "#### 7. Matplotlib – For visualizing the stock price and generate the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f872c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from telegram.ext import Updater, CommandHandler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc958196",
   "metadata": {},
   "source": [
    "### Why I have chosen Bi-Directional LSTM as the algorithm to use: ?\n",
    "\n",
    "#### 1. Capture long-term dependencies.\n",
    "\n",
    "#### 2. Contextual understanding – processing input forward and backwards.\n",
    "\n",
    "#### 3. Improved prediction accuracy.\n",
    "\n",
    "#### 4. Flexibility of predicting over multiple time horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871808c",
   "metadata": {},
   "source": [
    "### Why I have chosen the training time period for the BiLSTM model Jan 2022 to May 2023 ?\n",
    "\n",
    "#### 1. If time period is too low,  the model may not generalize well.\n",
    "#### 2.Therefore  it should be at-least an year long for ideal model training\n",
    "#### 3. If time period is too long, the model’s training time is drastically increased.\n",
    "#### 4. If the time period is around is around 6-7 years, the bi-directional LSTM takes too much time to train the model and generate the prediction results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9775b9",
   "metadata": {},
   "source": [
    "### Why Adam (Adaptive Moment Estiamtion) is suitable for stocks data ?\n",
    "\n",
    "#### 1. Adaptive learning rate :  Adaptability aids in handling the variables of stock data.\n",
    "\n",
    "#### 2. Faster convergence speeds. (Suitable when training models on limited resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ff7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(stock_name):\n",
    "    ticker = stock_name\n",
    "    train_start_date = '2022-01-01'\n",
    "    train_end_date = '2023-05-21'\n",
    "    test_start_date = '2023-05-22'\n",
    "    test_end_date = '2023-06-22'\n",
    "\n",
    "    train_data = yf.download(ticker, start=train_start_date, end=train_end_date)\n",
    "    test_data = yf.download(ticker, start=test_start_date, end=test_end_date)\n",
    "\n",
    "    train_data['Returns'] = train_data['Close'].pct_change() * 100\n",
    "    returns = train_data['Returns'].dropna().values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    returns = scaler.fit_transform(returns.reshape(-1, 1))\n",
    "\n",
    "    sequence_length = 20\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(sequence_length, len(returns)):\n",
    "        X.append(returns[i-sequence_length:i])\n",
    "        y.append(returns[i])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(50), input_shape=(sequence_length, 1))) #50 neurons in LSTM Layer.\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') #using ADAM optimizer.\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=16, verbose=2) #setting the epochs to 15 after multiple rounds of testing.\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    next_week_predictions = predictions.flatten()\n",
    "\n",
    "    dates = pd.date_range(start=test_start_date, periods=len(next_week_predictions), freq='B')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(dates, next_week_predictions, label='Predicted Returns')\n",
    "\n",
    "    # Calculate the expected monthly returns for the test period\n",
    "    monthly_returns = test_data['Close'].pct_change().resample('M').sum().values * 100\n",
    "    monthly_dates = pd.date_range(start=test_start_date, end=test_end_date, freq='M')\n",
    "\n",
    "# Repeat the monthly returns for each trading day within the corresponding month\n",
    "    trading_days_per_month = len(dates) // len(monthly_dates)\n",
    "    daily_monthly_returns = np.repeat(monthly_returns, trading_days_per_month)[:len(dates)]\n",
    "\n",
    "# Handling outliers and missing data : Pad the daily monthly returns with NaN values for the extra trading day\n",
    "    if len(daily_monthly_returns) < len(dates):\n",
    "        daily_monthly_returns = np.append(daily_monthly_returns, np.nan)\n",
    "\n",
    "    plt.plot(dates, daily_monthly_returns, label='Reference Line', marker='o')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Returns')\n",
    "    plt.title('Predicted Returns for the period of May 22nd to August 22nd')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.savefig('prediction.png', dpi=300)\n",
    "    plt.close()\n",
    "    return 'prediction.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185a296",
   "metadata": {},
   "source": [
    "## The workflow of the above generate_image function :\n",
    "\n",
    "### 1 . Data Retrieval and Preprocessing:\n",
    "    Download historical stock price data for the specified stock name within the defined train and test date ranges.\n",
    "    Calculate the percentage returns of the closing prices and store them in the 'Returns' column.\n",
    "    Scale the returns using the MinMaxScaler to normalize them within the range of -1 to 1.\n",
    "\n",
    "### 2. Sequence Generation:\n",
    "    Define a sequence length and create input sequences (X) and corresponding target values (y) for the LSTM model.\n",
    "    Slide a window of the sequence length through the returns data and extract the sequences and target values.\n",
    "\n",
    "### 3. Data Splitting:\n",
    "    Split the generated sequences and target values into training and testing sets.\n",
    "    Using 80% for training and 20% for testing.\n",
    "    \n",
    "### 4. Model Building and Training:\n",
    "    Create a Sequential model and add a Bidirectional LSTM layer with 50 neurons.\n",
    "    Add a Dense layer for the output and compile the model with mean squared error loss and Adam optimizer.\n",
    "    Train the model using the training data for 15 epochs and a batch size of 16.\n",
    "\n",
    "### 5. Prediction and Post-processing:\n",
    "    Use the trained model to make predictions on the testing data.\n",
    "    Inverse transform the predicted and actual values using the scaler to obtain the original scale of returns.\n",
    "    Flatten the predictions for the next week's returns.\n",
    "\n",
    "### 6. Visualization and Output:\n",
    "    Generate a line graph to visualize the predicted returns for the next quarter.\n",
    "    Save the graph as 'prediction.png' and return the filename as the output.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e1ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handler for the /start command\n",
    "def start(update, context):\n",
    "    context.bot.send_message(chat_id=update.effective_chat.id, text=\"Welcome to the Saathyak Kasuganti's stock trend prediction bot.\")\n",
    "    context.bot.send_message(chat_id=update.effective_chat.id, text=\"Use any stock symbol, to recieve stock price trend for the next quarter\")\n",
    "    context.bot.send_message(chat_id=update.effective_chat.id, text=\"enter /stock followed by any stock ticker or symbol. example: (/stock AAPL)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b56d8",
   "metadata": {},
   "source": [
    "### The above context.bot messages welcome the user to the telegram bot and prompt and guide the user to enter the appropriate stock symbol input for the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef45053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handler for the /stock command\n",
    "def stock(update, context):\n",
    "    stock_name = context.args[0]  # Extract the stock name from the command arguments\n",
    "    image_path = generate_image(stock_name)  # Generate the image from the graph.\n",
    "\n",
    "    # Debugging: Print the image path to the console\n",
    "    print(\"Image Path:\", image_path)\n",
    "\n",
    "    try:\n",
    "        context.bot.send_photo(chat_id=update.effective_chat.id, photo=open(image_path, 'rb'))  # Send the image as a reply\n",
    "\n",
    "        # Debugging: Print a success message to the console\n",
    "        print(\"Image sent successfully!\")\n",
    "    except Exception as e:\n",
    "        # Debugging: Print an error message and the exception to the console\n",
    "        print(\"Error sending image:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfa755",
   "metadata": {},
   "source": [
    "### Next step is the main function that contains the-bot token and invokes the other two functions, when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b59b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Setting up the Telegram bot\n",
    "    bot_token = '6257363048:AAHGybx4K_moPCC2UrIWGbHw7U7cydUL_BA'  #the telegram bot token that has been generated by BotFather.\n",
    "    updater = Updater(token=bot_token, use_context=True)\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Registering command handlers\n",
    "    start_handler = CommandHandler('start', start)\n",
    "    stock_handler = CommandHandler('stock', stock)\n",
    "    dispatcher.add_handler(start_handler)\n",
    "    dispatcher.add_handler(stock_handler)\n",
    "\n",
    "    # Debugging Step: Printing a message when the bot starts\n",
    "    print(\"Bot started!\")\n",
    "\n",
    "    # Starting the bot\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532d449",
   "metadata": {},
   "source": [
    "### Finally - Calling the main function to start the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42afd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot started!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 5s - loss: 0.0960 - 5s/epoch - 320ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0917 - 169ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0903 - 168ms/epoch - 10ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0900 - 170ms/epoch - 10ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0908 - 168ms/epoch - 10ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0916 - 168ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0894 - 178ms/epoch - 10ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0893 - 176ms/epoch - 10ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0900 - 170ms/epoch - 10ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0892 - 175ms/epoch - 10ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0887 - 175ms/epoch - 10ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0899 - 174ms/epoch - 10ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0887 - 179ms/epoch - 11ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0894 - 197ms/epoch - 12ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0896 - 169ms/epoch - 10ms/step\n",
      "3/3 [==============================] - 1s 6ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 6s - loss: 0.0848 - 6s/epoch - 330ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0815 - 164ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0819 - 171ms/epoch - 10ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0827 - 177ms/epoch - 10ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0817 - 170ms/epoch - 10ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0818 - 171ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0815 - 170ms/epoch - 10ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0817 - 168ms/epoch - 10ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0825 - 169ms/epoch - 10ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0820 - 189ms/epoch - 11ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0819 - 177ms/epoch - 10ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0820 - 176ms/epoch - 10ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0812 - 170ms/epoch - 10ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0815 - 185ms/epoch - 11ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0812 - 174ms/epoch - 10ms/step\n",
      "3/3 [==============================] - 1s 7ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 5s - loss: 0.0796 - 5s/epoch - 301ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0793 - 173ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0788 - 169ms/epoch - 10ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0784 - 191ms/epoch - 11ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0783 - 179ms/epoch - 11ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0785 - 175ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0783 - 179ms/epoch - 11ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0783 - 177ms/epoch - 10ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0782 - 175ms/epoch - 10ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0781 - 175ms/epoch - 10ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0780 - 176ms/epoch - 10ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0782 - 175ms/epoch - 10ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0781 - 187ms/epoch - 11ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0780 - 179ms/epoch - 11ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0782 - 176ms/epoch - 10ms/step\n",
      "3/3 [==============================] - 1s 5ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 6s - loss: 0.0546 - 6s/epoch - 348ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0540 - 176ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0537 - 184ms/epoch - 11ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0539 - 173ms/epoch - 10ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0543 - 173ms/epoch - 10ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0535 - 173ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0541 - 175ms/epoch - 10ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0539 - 176ms/epoch - 10ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0535 - 186ms/epoch - 11ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0536 - 177ms/epoch - 10ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0539 - 180ms/epoch - 11ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0537 - 177ms/epoch - 10ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0535 - 179ms/epoch - 11ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0536 - 179ms/epoch - 11ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0546 - 187ms/epoch - 11ms/step\n",
      "3/3 [==============================] - 1s 5ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 6s - loss: 0.0797 - 6s/epoch - 371ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0700 - 164ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0706 - 174ms/epoch - 10ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0693 - 168ms/epoch - 10ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0692 - 176ms/epoch - 10ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0687 - 172ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0699 - 173ms/epoch - 10ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0689 - 175ms/epoch - 10ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0707 - 203ms/epoch - 12ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0689 - 191ms/epoch - 11ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0698 - 197ms/epoch - 12ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0689 - 193ms/epoch - 11ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0692 - 200ms/epoch - 12ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0697 - 174ms/epoch - 10ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0687 - 178ms/epoch - 10ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002142029BA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 6ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/15\n",
      "17/17 - 5s - loss: 0.0705 - 5s/epoch - 323ms/step\n",
      "Epoch 2/15\n",
      "17/17 - 0s - loss: 0.0689 - 176ms/epoch - 10ms/step\n",
      "Epoch 3/15\n",
      "17/17 - 0s - loss: 0.0696 - 176ms/epoch - 10ms/step\n",
      "Epoch 4/15\n",
      "17/17 - 0s - loss: 0.0694 - 174ms/epoch - 10ms/step\n",
      "Epoch 5/15\n",
      "17/17 - 0s - loss: 0.0686 - 176ms/epoch - 10ms/step\n",
      "Epoch 6/15\n",
      "17/17 - 0s - loss: 0.0685 - 166ms/epoch - 10ms/step\n",
      "Epoch 7/15\n",
      "17/17 - 0s - loss: 0.0684 - 170ms/epoch - 10ms/step\n",
      "Epoch 8/15\n",
      "17/17 - 0s - loss: 0.0682 - 189ms/epoch - 11ms/step\n",
      "Epoch 9/15\n",
      "17/17 - 0s - loss: 0.0685 - 176ms/epoch - 10ms/step\n",
      "Epoch 10/15\n",
      "17/17 - 0s - loss: 0.0681 - 176ms/epoch - 10ms/step\n",
      "Epoch 11/15\n",
      "17/17 - 0s - loss: 0.0700 - 178ms/epoch - 10ms/step\n",
      "Epoch 12/15\n",
      "17/17 - 0s - loss: 0.0696 - 176ms/epoch - 10ms/step\n",
      "Epoch 13/15\n",
      "17/17 - 0s - loss: 0.0688 - 181ms/epoch - 11ms/step\n",
      "Epoch 14/15\n",
      "17/17 - 0s - loss: 0.0683 - 177ms/epoch - 10ms/step\n",
      "Epoch 15/15\n",
      "17/17 - 0s - loss: 0.0686 - 192ms/epoch - 11ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021413AFB940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 6ms/step\n",
      "Image Path: prediction.png\n",
      "Image sent successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297fd7f7",
   "metadata": {},
   "source": [
    "### Result Interpretation:\n",
    "#### The Results above indicate that 17 batches of data are used in the training steps.\n",
    "#### The first epoch takes the longest time as it involves initialization steps\n",
    "#### each subsequent epoch takes around 150ms only.\n",
    "#### Initial loss is around 10%. \n",
    "#### By the end of the training phase, the loss is reduced by some extent to 8.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12371c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
